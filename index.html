<!DOCTYPE HTML>
<html lang="en" xmlns="">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-CSSRCE808M"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-CSSRCE808M');
    </script>

    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ehsan Pajouheshgar</title>

    <meta name="author" content="Ehsan Pajouheshgar">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="images/favicon.png">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Ehsan Pajouheshgar</name>
                        </p>
                        <p>
                            I am currently a 4th year PhD candidate at EPFL Lausanne pursuing my doctoral studies under
                            supervision of Sabine SÃ¼sstrunk at <a href="https://www.epfl.ch/labs/ivrl/"> Image and
                            Visual Representation Laboratory (IVRL)</a> .
                            Before joining EPFL, I did my bachelor's degree at Sharif University of
                            Technology in Iran majoring in Computer Engineering and a minor in Mathematics.
                        </p>

                        <p>
                            My research in the last years has been focused on studying Neural Cellular Automata (NCA)
                            models. NCAs demonstrate how self-organization and complexity can emerge from simple local
                            interactions. The advantage of NCAs over traditional Cellular Automata is that they are
                            differentiable and can be trained with gradient-based methods.

                            I'm also interested in Computer Vision and Computer Graphics. I like
                            to design (bio and physics)-inspired models to tackle different problems in these fields.
                            More recently, I am learning and doing research on Artificial Life. I am interested in
                            the emergence of life-like behaviors such as Solitons, Self-Organization, and
                            Self-Replication.

                        </p>

                        <!--                        <p>-->
                        <!--                            During the summer of 2018, I had the opportunity to undertake an internship at <a-->
                        <!--                                href="https://ist.ac.at/en/home/">IST Austria</a>-->
                        <!--                            where I was mentored by Christoph Lampert. In the following year, from 2019 to 2020, I-->
                        <!--                            worked as a Data Scientist at <a href="https://balad.ir/">Balad</a>, a dynamic company-->
                        <!--                            dedicated to the development of advanced map and navigation software.-->
                        <!--                        </p>-->
                        <!--                        <p>-->
                        <!--                            During my high school years, I developed a strong passion for Physics and dedicated-->
                        <!--                            considerable effort to preparing for the national physics Olympiad, where I was able to-->
                        <!--                            achieve the 7th rank among a vast pool of nearly 100 thousand participants and earn a gold-->
                        <!--                            medal.-->
                        <!--                            <br>-->

                        <!--                            Throughout my bachelor's degree, I found myself deeply intrigued by the world of probability-->
                        <!--                            and statistics. My interest led me to take part in the national statistics Olympiad, where I-->
                        <!--                            achieved the 1st place among hundreds of participants and awarded a gold medal.-->


                        </p>
                        <p style="text-align:center">

                            <a href="mailto:e.pajouheshgar@gmail.com">Email</a> &nbsp/&nbsp
                            <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                            <!--                            <a href="https://www.linkedin.com/in/yitao-xu-b016891b2/">Linkedin</a> &nbsp/&nbsp-->
                            <a href="https://scholar.google.com/citations?user=bddQ6pQAAAAJ&hl=en">Google Scholar</a>
                            &nbsp/&nbsp
                            <a href="https://github.com/TheDevilWillBeBee">Github</a>
                        </p>

                        <p style="text-align:center">
                            <b> Navigate this page </b>
                            <br>
                            <a href="#awards">Awards</a> &nbsp/&nbsp
                            <a href="#publications">Publications</a> &nbsp/&nbsp
                            <!--                            <a href="https://www.linkedin.com/in/yitao-xu-b016891b2/">Linkedin</a> &nbsp/&nbsp-->
                            <a href="#news">News</a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/photo.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                                                        src="images/photo.jpg" class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>
            <table id="awards"
                   style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <th style="text-align:center;" colspan="2">
                        <heading>Awards &#127942;</heading>
                    </th>
                </tr>
                <tr>
                    <td><br></td>
                </tr>
                <tr>
                    <td>Dec. 2023</td>
                    <td><b>Teaching Assistance Excellence Award</b> From EPFL</td>
                </tr>
                <tr>
                    <td>Aug. 2022</td>
                    <td><b>Best Paper Award</b> From SIGGRAPH 2022 Conference</td>
                </tr>
                <tr>
                    <td>Oct. 2020</td>
                    <td><b>Doctoral Fellowship</b> for one year from EDIC EPFL</td>
                </tr>
                <tr>
                    <td>Sept. 2019</td>
                    <td><b>Gold Medal</b> in Iranian National <b>Statistics Olympiad</b></td>
                </tr>
                <tr>
                    <td>Aug. 2014</td>
                    <td><b>Gold Medal</b> in Iranian National <b>Physics Olympiad</b></td>
                </tr>

                <tr>
                    <td><br></td>
                </tr>
                </tbody>
            </table>


            <br><br>
            <table id="publications"
                   style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <th colspan="2" style="text-align:center;">
                    <heading>Publication Highlights &#128220;</heading>
                </th>

                <tr onmouseout="meshnca_stop()" onmouseover="meshnca_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='meshnca_image'>
                                <video width=100% height=100% muted autoplay loop>
                                    <source src="images/meshnca.mp4" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src='images/meshnca.png' width="160">
                        </div>
                        <script type="text/javascript">
                            function meshnca_start() {
                                document.getElementById('meshnca_image').style.opacity = "1";
                            }

                            function meshnca_stop() {
                                if (detectMob()) {
                                    document.getElementById('meshnca_image').style.opacity = "1";
                                } else {
                                    document.getElementById('meshnca_image').style.opacity = "0";
                                }
                            }

                            meshnca_start()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://meshnca.github.io">
                            <papertitle>Mesh Neural Cellular Automata
                            </papertitle>
                        </a>
                        <br>
                        <strong>Ehsan Pajouheshgar*</strong>,
                        Yitao Xu*,
                        Alexander Mordvintsev,
                        Eyvind Niklasson,
                        Tong Zhang,
                        Sabine SÃ¼sstrunk
                        <br>
                        <em>SIGGRAPH</em>, 2024
                        <br>
                        <a href="https://meshnca.github.io/">Demo</a>
                        /
                        <a href="https://arxiv.org/abs/2311.02820">arXiv</a>
                        /
                        <a href="https://github.com/IVRL/MeshNCA">code</a>
                        <p></p>
                        <p>
                            MeshNCA is a type of <b>N</b>eural <b>C</b>ellular <b>A</b>utomata that can operate
                            on cells arranged on a 3D mesh. MeshNCA can simultaneously generate multiple textures
                            (albedo, normal, roughness, ...) for Physically-based-rendering (PBR).
                            It also enables grafting multiple NCA models on each other to create mixture of textures.
                            Checkout the <a href="https://meshnca.github.io/">demo</a>!
                        </p>
                        <p>
                        </p>
                    </td>
                </tr>

                <tr onmouseout="noisenca_stop()" onmouseover="noisenca_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='noisenca_image'>
                                <video width=100% height=100% muted autoplay loop>
                                    <source src="images/noisenca.mp4" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src='images/noisenca.png' width="160">
                        </div>
                        <script type="text/javascript">
                            function noisenca_start() {
                                document.getElementById('noisenca_image').style.opacity = "1";
                            }

                            function noisenca_stop() {
                                if (detectMob()) {
                                    document.getElementById('noisenca_image').style.opacity = "1";
                                } else {
                                    document.getElementById('noisenca_image').style.opacity = "0";
                                }
                            }

                            noisenca_start()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://noisenca.github.io">
                            <papertitle>NoiseNCA: Noisy Seed Improves Spatio-Temporal Continuity of Neural Cellular
                                Automata
                            </papertitle>
                        </a>
                        <br>
                        <strong>Ehsan Pajouheshgar</strong>,
                        Yitao Xu,
                        Sabine SÃ¼sstrunk
                        <br>
                        <em>Artificial Life (ALife)</em>, 2024
                        <br>
                        <a href="https://noisenca.github.io/">Demo</a>
                        /
                        <a href="https://arxiv.org/abs/2404.06279">arXiv</a>
                        /
                        <a href="">Coming soon</a>
                        <p></p>
                        <p>
                            We propose a small change to Neural Cellular Automata (NCA) and show that the update rule
                            learned by NoiseNCA
                            actually correspond to a continuous space-time Partial Differential Equation (PDE).
                            Utilizing this emergent space-time continuity, NoiseNCA allows changing the speed of the
                            pattern formation
                            and the scale of the patterns at inference time.
                            Checkout the <a href="https://noisenca.github.io/">demo</a>!
                        </p>
                        <p>
                        </p>
                    </td>
                </tr>

                <tr onmouseout="dynca_stop()" onmouseover="dynca_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='dynca_image'>
                                <video width=100% height=100% muted autoplay loop>
                                    <source src="images/dynca.mp4" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src='images/dynca.png' width="160">
                        </div>
                        <script type="text/javascript">
                            function dynca_start() {
                                document.getElementById('dynca_image').style.opacity = "1";
                            }

                            function dynca_stop() {
                                if (detectMob()) {
                                    document.getElementById('dynca_image').style.opacity = "1";
                                } else {
                                    document.getElementById('dynca_image').style.opacity = "0";
                                }
                            }

                            dynca_start()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://dynca.github.io">
                            <papertitle>DyNCA: Real-time Dynamic Texture Synthesis Using Neural Cellular Automata
                            </papertitle>
                        </a>
                        <br>
                        <strong>Ehsan Pajouheshgar*</strong>,
                        Yitao Xu*,
                        Tong Zhang,
                        Sabine SÃ¼sstrunk
                        <br>
                        <em>CVPR</em>, 2023
                        <br>
                        <a href="https://dynca.github.io/">Demo</a>
                        /
                        <a href="https://arxiv.org/abs/2211.11417">arXiv</a>
                        /
                        <a href="https://github.com/IVRL/DyNCA">code</a>
                        <p></p>
                        <p>
                            Dynamic Neural Cellular Automata (DyNCA), is a method that enables real-time and
                            controllable dynamic texture synthesis. Checkout the <a
                                href="https://dynca.github.io/">demo</a>!
                        </p>
                        <p>
                        </p>
                    </td>
                </tr>


                <tr bgcolor="ffffd0">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/clipasso.png' width="160">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://clipasso.github.io/clipasso/">
                            <papertitle>CLIPasso: Semantically-Aware Object Sketching
                            </papertitle>
                        </a>
                        <br>
                        Yael Vinker, <strong>Ehsan Pajouheshgar</strong>, Jessica Y. Bo, Roman Bachmann, <br>
                        Amit Haim Bermano, Daniel Cohen-Or, Amir Zamir, Ariel Shamir
                        <br>
                        <em>SIGGRAPH</em>, 2022
                        <font color="red"> <strong> (Best Paper Award) </strong> </font>
                        <br>
                        <a href="https://clipasso.github.io/clipasso/">Project Page</a> /
                        <a href="https://replicate.com/yael-vinker/clipasso">Demo</a> /
                        <a href="https://arxiv.org/abs/2202.05822">arXiv</a> /
                        <a href="https://github.com/yael-vinker/CLIPasso">code</a>
                        <p></p>
                        <p>
                            Our work converts an image of an object to a sketch, allowing for varying levels of
                            abstraction, while preserving its key visual features.
                        </p>
                        <p>
                        </p>
                    </td>

                </tr>


                </tbody>


            </table>

            <br><br>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <th colspan="2" style="text-align:center;">
                    <heading>Publications &#128220;</heading>
                </th>


                <tr onmouseout="emdnca_stop()" onmouseover="emdnca_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='emd_nca_image'>
                                <video width=100% height=100% muted autoplay loop>
                                    <source src="images/emergent_dynamics_nca.mp4" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src='images/emergent_dynamics_nca.png' width="160">
                        </div>
                        <script type="text/javascript">
                            function emdnca_start() {
                                document.getElementById('emd_nca_image').style.opacity = "1";
                            }

                            function emdnca_stop() {
                                if (detectMob()) {
                                    document.getElementById('emd_nca_image').style.opacity = "1";
                                } else {
                                    document.getElementById('emd_nca_image').style.opacity = "0";
                                }
                            }

                            emdnca_start()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2111.12583">
                            <papertitle>Emergent Dynamics in Neural Cellular Automata
                            </papertitle>
                        </a>
                        <br>
                        Yitao Xu, <strong>Ehsan Pajouheshgar</strong>, Sabine SÃ¼sstrunk
                        <br>
                        <em>Artificial Life (ALife)</em>, 2022
                        <br>
                        <a href="https://arxiv.org/abs/2404.06406">arXiv</a> /
                        <a href="">Coming Soon</a>
                        <p></p>
                        <p>
                            Trained Neural Cellular Automata (NCA) models exhibit many emergent behaviors, such as
                            self-organization, and spontaneous motion. In this paper we investigate the spontaneous
                            motion property
                            of NCAs. We find that the ratio between the number of channels in the cell state
                            and the number of hidden neurons in the update rule is a key factor that controls the
                            NCA stability and emergent motion in the NCA generated patterns.

                        </p>
                        <p>
                        </p>
                    </td>

                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/lelsd.png' width="160">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2111.12583">
                            <papertitle>Optimizing Latent Space Directions For GAN-based Local Image Editing
                            </papertitle>
                        </a>
                        <br>
                        <strong>Ehsan Pajouheshgar</strong>, Tong Zhang, Sabine SÃ¼sstrunk
                        <br>
                        <em>ICASSP</em>, 2022
                        <br>
                        <a href="https://arxiv.org/abs/2111.12583">arXiv</a> /
                        <a href="https://github.com/IVRL/LELSD">code</a>
                        <p></p>
                        <p>
                            We introduce the Locally Effective Latent Space Direction (LELSD) framework, a novel
                            approach to localized image editing in Generative Adversarial Networks (GANs), which
                            utilizes a new objective function incorporating supervision from a pre-trained segmentation
                            network.
                        </p>
                        <p>
                        </p>
                    </td>

                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/ptf.png' width="160">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/1812.02984.pdf">
                            <papertitle>Back to square one: probabilistic trajectory forecasting without bells and
                                whistles
                            </papertitle>
                        </a>
                        <br>
                        <strong>Ehsan Pajouheshgar</strong>, Christoph H. Lampert
                        <br>
                        <em>NeurIPS 2018</em>,
                        <small> (Workshop on Modeling and Decision-Making in the Spatiotemporal Domain)</small>
                        <br>
                        <a href="https://arxiv.org/abs/2111.12583">arXiv</a>
                        <p></p>
                        <p>
                            We present an uncomplicated non-parametric baseline that attains the lowest error based on a
                            widely adopted metric within the field. This serves to demonstrate the misleading nature of
                            this particular metric.
                        </p>
                        <p>
                        </p>
                    </td>
                </tr>


                </tbody>


            </table>


            <table id="news"
                   style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <th style="text-align:center;" colspan="2">
                        <heading>News &#128240;</heading>
                    </th>
                </tr>
                <tr>
                    <td><br></td>
                </tr>
                <tr>
                    <td>July. 2024</td>
                    <td>I will attend <b>Siggraph 2024</b> Conference (&#129310; on visa). Let's meet there!</td>
                </tr>
                <tr>
                    <td>July. 2024</td>
                    <td>I will attend <b>Artificial Life (ALife 2024)</b> Conference. Let's meet there!</td>
                </tr>
                <tr>
                    <td>May. 2023</td>
                    <td>Two papers accepted to ALife 2024.</td>
                </tr>
                <tr>
                    <td>Mar. 2023</td>
                    <td>MeshNCA was accepted as a journal paper to SIGGRAPH 2024.</td>
                </tr>


                <tr>
                    <td><br></td>
                </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            <a href="https://jonbarron.info/">Webpage Template</a>
                            <br>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>
</body>
<script>
    function detectMob() {
        return false;
        const toMatch = [
            /Android/i,
            /webOS/i,
            /iPhone/i,
            /iPad/i,
            /iPod/i,
            /BlackBerry/i,
            /Windows Phone/i
        ];

        return toMatch.some((toMatchItem) => {
            return navigator.userAgent.match(toMatchItem);
        });
    }
</script>
</html>

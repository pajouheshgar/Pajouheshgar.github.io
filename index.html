<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ehsan Pajouheshgar</title>

    <meta name="author" content="Ehsan Pajouheshgar">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon"
          href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåè</text></svg>">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Ehsan Pajouheshgar</name>
                        </p>
                        <p>
                            I am currently a 3rd year PhD candidate at EPFL Lausanne pursuing my doctoral studies under
                            supervision of Sabine S√ºsstrunk at <a href="https://www.epfl.ch/labs/ivrl/"> Image and
                            Visual Representation Laboratory (IVRL)</a> .
                            Before joining EPFL, I did my bachelor's degree in Computer Engineering at
                            Sharif University of Technology in Iran.
                        </p>
                        <p>
                            During the summer of 2018, I had the opportunity to undertake an internship at <a
                                href="https://ist.ac.at/en/home/">IST Austria</a>
                            where I was mentored by Christoph Lampert. In the following year, from 2019 to 2020, I
                            worked as a Data Scientist at <a href="https://balad.ir/">Balad</a>, a dynamic company
                            dedicated to the development of advanced map and navigation software.
                        </p>
                        <p>
                            During my high school years, I developed a strong passion for Physics and dedicated
                            considerable effort to preparing for the national physics Olympiad, where I was able to
                            achieve the 7th rank among a vast pool of nearly 100 thousand participants and earn a gold
                            medal.
                            <br>

                            Throughout my bachelor's degree, I found myself deeply intrigued by the world of probability
                            and statistics. My interest led me to take part in the national statistics Olympiad, where I
                            was able to secure a gold medal and achieve the 1st place among hundreds of participants.


                        </p>
                        <p style="text-align:center">
                            <a href="mailto:e.pajouheshgar@gmail.com">Email</a> &nbsp/&nbsp
                            <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                            <!--                            <a href="https://www.linkedin.com/in/yitao-xu-b016891b2/">Linkedin</a> &nbsp/&nbsp-->
                            <a href="https://scholar.google.com/citations?user=bddQ6pQAAAAJ&hl=en">Google Scholar</a>
                            &nbsp/&nbsp
                            <a href="https://github.com/TheDevilWillBeBee">Github</a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/photo.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                                                        src="images/photo.jpg" class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <th style="text-align:center;">
                        <heading>Research</heading>
                    </th>
                </tr>
                <tr>
                    <!-- <td style="padding:20px;width:100%;vertical-align:middle"> -->
                    <td>
                        <p>
                            I'm interested in Computer Vision and Computer Graphics, and Machine Learning. I like to
                            design simple
                            (physics and bio)-inspired models to efficiently solve different tasks in Computer Vision and Computer
                            Graphics. At the moment, my research is focused on
                        <ul>
                            <li>Neural cellular automata models and self-organizing systems</li>
                            <li>Texture Synthesis</li>
                            <li>Role of textures in visual perception</li>

                        </ul>



                        </p>
                    </td>
                    <!-- </td> -->
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <th colspan="2" style="text-align:center;">
                    <heading>Publications</heading>
                    <!--                    <br><span style="color:gray;">"*" means equal contribution</span></th>-->
                    <tr onmouseout="dynca_stop()" onmouseover="dynca_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                        <div class="two" id='dynca_image'>
                            <video width=100% height=100% muted autoplay loop>
                                <source src="images/dynca.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                        </div>
                        <img src='images/dynca.png' width="160">
                    </div>
                    <script type="text/javascript">
                        function dynca_start() {
                            document.getElementById('dynca_image').style.opacity = "1";
                        }

                        function dynca_stop() {
                            document.getElementById('dynca_image').style.opacity = "0";
                        }

                        dynca_stop()
                    </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://dynca.github.io">
                        <papertitle>DyNCA: Real-time Dynamic Texture Synthesis Using Neural Cellular Automata
                        </papertitle>
                    </a>
                    <br>
                    <strong>Ehsan Pajouheshgar*</strong>,
                    Yitao Xu*,
                    Tong Zhang,
                    Sabine S√ºsstrunk
                    <br>
                    <em>CVPR</em>, 2023
                    <br>
                    <a href="https://dynca.github.io/">Demo</a>
                    /
                    <a href="https://arxiv.org/abs/2211.11417">arXiv</a>
                    /
                    <a href="https://github.com/IVRL/DyNCA">code</a>
                    <p></p>
                    <p>
                        Dynamic Neural Cellular Automata (DyNCA), is a method that enables real-time and
                        controllable dynamic texture synthesis. Checkout the <a href="https://dynca.github.io/">demo</a>!
                    </p>
                    <p>
                    </p>
                </td>


                <tr bgcolor="ffffd0">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/clipasso.png' width="160">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://clipasso.github.io/clipasso/">
                            <papertitle>CLIPasso: Semantically-Aware Object Sketching
                            </papertitle>
                        </a>
                        <br>
                        Yael Vinker, <strong>Ehsan Pajouheshgar</strong>, Jessica Y. Bo, Roman Bachmann, <br>
                        Amit Haim Bermano, Daniel Cohen-Or, Amir Zamir, Ariel Shamir
                        <br>
                        <em>SIGGRAPH</em>, 2022
                        <font color="red"> <strong> (Best Paper Award) </strong> </font>
                        <br>
                        <a href="https://clipasso.github.io/clipasso/">Project Page</a> /
                        <a href="https://replicate.com/yael-vinker/clipasso">Demo</a> /
                        <a href="https://arxiv.org/abs/2202.05822">arXiv</a> /
                        <a href="https://github.com/yael-vinker/CLIPasso">code</a>
                        <p></p>
                        <p>
                            Our work converts an image of an object to a sketch, allowing for varying levels of
                            abstraction, while preserving its key visual features.
                        </p>
                        <p>
                        </p>
                    </td>


                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/lelsd.png' width="160">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2111.12583">
                            <papertitle>Optimizing Latent Space Directions For GAN-based Local Image Editing
                            </papertitle>
                        </a>
                        <br>
                        <strong>Ehsan Pajouheshgar</strong>, Tong Zhang, Sabine S√ºsstrunk
                        <br>
                        <em>ICASSP</em>, 2022
                        <br>
                        <a href="https://arxiv.org/abs/2111.12583">arXiv</a> /
                        <a href="https://github.com/IVRL/LELSD">code</a>
                        <p></p>
                        <p>
                            We introduce the Locally Effective Latent Space Direction (LELSD) framework, a novel
                            approach to localized image editing in Generative Adversarial Networks (GANs), which
                            utilizes a new objective function incorporating supervision from a pre-trained segmentation
                            network.
                        </p>
                        <p>
                        </p>
                    </td>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/ptf.png' width="160">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/1812.02984.pdf">
                            <papertitle>Back to square one: probabilistic trajectory forecasting without bells and
                                whistles
                            </papertitle>
                        </a>
                        <br>
                        <strong>Ehsan Pajouheshgar</strong>, Christoph H. Lampert
                        <br>
                        <em>NeurIPS 2018</em>,
                        <small> (Workshop on Modeling and Decision-Making in the Spatiotemporal Domain)</small>
                        <br>
                        <a href="https://arxiv.org/abs/2111.12583">arXiv</a>
                        <p></p>
                        <p>
                            We present an uncomplicated non-parametric baseline that attains the lowest error based on a
                            widely adopted metric within the field. This serves to demonstrate the misleading nature of
                            this particular metric.
                        </p>
                        <p>
                        </p>
                    </td>


                </tbody>


            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            <a href="https://jonbarron.info/">Webpage Template</a>
                            <br>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>
</body>

</html>

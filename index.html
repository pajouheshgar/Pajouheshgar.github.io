<!DOCTYPE HTML>
<html lang="en" xmlns="">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-CSSRCE808M"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-CSSRCE808M');
    </script>

    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ehsan Pajouheshgar</title>

    <meta name="author" content="Ehsan Pajouheshgar">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="images/favicon.png">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Ehsan Pajouheshgar</name>
                        </p>
                        <p>
                            I am currently a 4th year PhD candidate at EPFL Lausanne pursuing my doctoral studies under
                            supervision of Sabine S端sstrunk at <a href="https://www.epfl.ch/labs/ivrl/"> Image and
                            Visual Representation Laboratory (IVRL)</a> .
                            Before joining EPFL, I did my bachelor's degree at Sharif University of
                            Technology in Iran majoring in Computer Engineering and a minor in Mathematics.
                        </p>

                        <p>
                            My research in the last years has been focused on studying Neural Cellular Automata (NCA)
                            models. NCAs demonstrate how self-organization and complexity can emerge from simple local
                            interactions. The advantage of NCAs over traditional Cellular Automata is that they are
                            differentiable and can be trained with gradient-based methods.

                            I'm also interested in Computer Vision and Computer Graphics. I like
                            to design (bio and physics)-inspired models to tackle different problems in these fields.
                            More recently, I am learning and doing research on Artificial Life. I am interested in
                            the emergence of life-like behaviors such as Solitons, Self-Organization, Self-Replication.

                        </p>

                        <!--                        <p>-->
                        <!--                            During the summer of 2018, I had the opportunity to undertake an internship at <a-->
                        <!--                                href="https://ist.ac.at/en/home/">IST Austria</a>-->
                        <!--                            where I was mentored by Christoph Lampert. In the following year, from 2019 to 2020, I-->
                        <!--                            worked as a Data Scientist at <a href="https://balad.ir/">Balad</a>, a dynamic company-->
                        <!--                            dedicated to the development of advanced map and navigation software.-->
                        <!--                        </p>-->
                        <!--                        <p>-->
                        <!--                            During my high school years, I developed a strong passion for Physics and dedicated-->
                        <!--                            considerable effort to preparing for the national physics Olympiad, where I was able to-->
                        <!--                            achieve the 7th rank among a vast pool of nearly 100 thousand participants and earn a gold-->
                        <!--                            medal.-->
                        <!--                            <br>-->

                        <!--                            Throughout my bachelor's degree, I found myself deeply intrigued by the world of probability-->
                        <!--                            and statistics. My interest led me to take part in the national statistics Olympiad, where I-->
                        <!--                            achieved the 1st place among hundreds of participants and awarded a gold medal.-->


                        </p>
                        <p style="text-align:center">
                            <a href="mailto:e.pajouheshgar@gmail.com">Email</a> &nbsp/&nbsp
                            <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                            <!--                            <a href="https://www.linkedin.com/in/yitao-xu-b016891b2/">Linkedin</a> &nbsp/&nbsp-->
                            <a href="https://scholar.google.com/citations?user=bddQ6pQAAAAJ&hl=en">Google Scholar</a>
                            &nbsp/&nbsp
                            <a href="https://github.com/TheDevilWillBeBee">Github</a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/photo.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                                                        src="images/photo.jpg" class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <th style="text-align:center;" colspan="2">
                        <heading>Awards</heading>
                    </th>
                </tr>
                <tr>
                    <td><br></td>
                </tr>
                <tr>
                    <td>Dec. 2023</td>
                    <td><b>Teaching Assistance Excellence Award</b> From EPFL</td>
                </tr>
                <tr>
                    <td>Aug. 2022</td>
                    <td><b>Best Paper Award</b> From SIGGRAPH 2022 Conference</td>
                </tr>
                <tr>
                    <td>Oct. 2020</td>
                    <td><b>Doctoral Fellowship</b> for one year from EDIC EPFL</td>
                </tr>
                <tr>
                    <td>Sept. 2019</td>
                    <td><b>Gold Medal</b> in Iranian National <b>Statistics Olympiad</b></td>
                </tr>
                <tr>
                    <td>Aug. 2014</td>
                    <td><b>Gold Medal</b> in Iranian National <b>Physics Olympiad</b></td>
                </tr>

                <tr>
                    <td><br></td>
                </tr>
                </tbody>
            </table>

            <br><br>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <th colspan="2" style="text-align:center;">
                    <heading>Publication Highlights</heading>
                </th>

                <tr onmouseout="meshnca_stop()" onmouseover="meshnca_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='meshnca_image'>
                                <video width=100% height=100% muted autoplay loop>
                                    <source src="images/meshnca.mp4" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src='images/meshnca.png' width="160">
                        </div>
                        <script type="text/javascript">
                            function meshnca_start() {
                                document.getElementById('meshnca_image').style.opacity = "1";
                            }

                            function meshnca_stop() {
                                if (detectMob()) {
                                    document.getElementById('meshnca_image').style.opacity = "1";
                                } else {
                                document.getElementById('meshnca_image').style.opacity = "0";
                                }
                            }

                            meshnca_start()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://meshnca.github.io">
                            <papertitle>Mesh Neural Cellular Automata
                            </papertitle>
                        </a>
                        <br>
                        <strong>Ehsan Pajouheshgar*</strong>,
                        Yitao Xu*,
                        Alexander Mordvintsev,
                        Eyvind Niklasson,
                        Tong Zhang,
                        Sabine S端sstrunk
                        <br>
                        <em>SIGGRAPH</em>, 2024
                        <br>
                        <a href="https://meshnca.github.io/">Demo</a>
                        /
                        <a href="https://arxiv.org/abs/2311.02820">arXiv</a>
                        /
                        <a href="https://github.com/IVRL/MeshNCA">code</a>
                        <p></p>
                        <p>
                            MeshNCA is a type of <b>N</b>eural <b>C</b>ellular <b>A</b>utomata that can operate
                            on cells arranged on a 3D mesh. MeshNCA can simultaneously generate multiple textures
                            (albedo, normal, roughness, ...) for Physically-based-rendering (PBR).
                            It also enables grafting multiple NCA models on each other to create mixture of textures.
                            Checkout the <a href="https://meshnca.github.io/">demo</a>!
                        </p>
                        <p>
                        </p>
                    </td>
                </tr>

                <tr onmouseout="dynca_stop()" onmouseover="dynca_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='dynca_image'>
                                <video width=100% height=100% muted autoplay loop>
                                    <source src="images/dynca.mp4" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src='images/dynca.png' width="160">
                        </div>
                        <script type="text/javascript">
                            function dynca_start() {
                                document.getElementById('dynca_image').style.opacity = "1";
                            }

                            function dynca_stop() {
                                if (detectMob()) {
                                    document.getElementById('dynca_image').style.opacity = "1";
                                } else {
                                    document.getElementById('dynca_image').style.opacity = "0";
                                }
                            }

                            dynca_start()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://dynca.github.io">
                            <papertitle>DyNCA: Real-time Dynamic Texture Synthesis Using Neural Cellular Automata
                            </papertitle>
                        </a>
                        <br>
                        <strong>Ehsan Pajouheshgar*</strong>,
                        Yitao Xu*,
                        Tong Zhang,
                        Sabine S端sstrunk
                        <br>
                        <em>CVPR</em>, 2023
                        <br>
                        <a href="https://dynca.github.io/">Demo</a>
                        /
                        <a href="https://arxiv.org/abs/2211.11417">arXiv</a>
                        /
                        <a href="https://github.com/IVRL/DyNCA">code</a>
                        <p></p>
                        <p>
                            Dynamic Neural Cellular Automata (DyNCA), is a method that enables real-time and
                            controllable dynamic texture synthesis. Checkout the <a
                                href="https://dynca.github.io/">demo</a>!
                        </p>
                        <p>
                        </p>
                    </td>
                </tr>


                <tr bgcolor="ffffd0">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/clipasso.png' width="160">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://clipasso.github.io/clipasso/">
                            <papertitle>CLIPasso: Semantically-Aware Object Sketching
                            </papertitle>
                        </a>
                        <br>
                        Yael Vinker, <strong>Ehsan Pajouheshgar</strong>, Jessica Y. Bo, Roman Bachmann, <br>
                        Amit Haim Bermano, Daniel Cohen-Or, Amir Zamir, Ariel Shamir
                        <br>
                        <em>SIGGRAPH</em>, 2022
                        <font color="red"> <strong> (Best Paper Award) </strong> </font>
                        <br>
                        <a href="https://clipasso.github.io/clipasso/">Project Page</a> /
                        <a href="https://replicate.com/yael-vinker/clipasso">Demo</a> /
                        <a href="https://arxiv.org/abs/2202.05822">arXiv</a> /
                        <a href="https://github.com/yael-vinker/CLIPasso">code</a>
                        <p></p>
                        <p>
                            Our work converts an image of an object to a sketch, allowing for varying levels of
                            abstraction, while preserving its key visual features.
                        </p>
                        <p>
                        </p>
                    </td>

                </tr>


                </tbody>


            </table>

            <br><br>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <th colspan="2" style="text-align:center;">
                    <heading>Publications</heading>
                </th>


                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/lelsd.png' width="160">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2111.12583">
                            <papertitle>Optimizing Latent Space Directions For GAN-based Local Image Editing
                            </papertitle>
                        </a>
                        <br>
                        <strong>Ehsan Pajouheshgar</strong>, Tong Zhang, Sabine S端sstrunk
                        <br>
                        <em>ICASSP</em>, 2022
                        <br>
                        <a href="https://arxiv.org/abs/2111.12583">arXiv</a> /
                        <a href="https://github.com/IVRL/LELSD">code</a>
                        <p></p>
                        <p>
                            We introduce the Locally Effective Latent Space Direction (LELSD) framework, a novel
                            approach to localized image editing in Generative Adversarial Networks (GANs), which
                            utilizes a new objective function incorporating supervision from a pre-trained segmentation
                            network.
                        </p>
                        <p>
                        </p>
                    </td>

                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/ptf.png' width="160">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/1812.02984.pdf">
                            <papertitle>Back to square one: probabilistic trajectory forecasting without bells and
                                whistles
                            </papertitle>
                        </a>
                        <br>
                        <strong>Ehsan Pajouheshgar</strong>, Christoph H. Lampert
                        <br>
                        <em>NeurIPS 2018</em>,
                        <small> (Workshop on Modeling and Decision-Making in the Spatiotemporal Domain)</small>
                        <br>
                        <a href="https://arxiv.org/abs/2111.12583">arXiv</a>
                        <p></p>
                        <p>
                            We present an uncomplicated non-parametric baseline that attains the lowest error based on a
                            widely adopted metric within the field. This serves to demonstrate the misleading nature of
                            this particular metric.
                        </p>
                        <p>
                        </p>
                    </td>
                </tr>


                </tbody>


            </table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            <a href="https://jonbarron.info/">Webpage Template</a>
                            <br>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>
</body>
<script>
    function detectMob() {
    const toMatch = [
        /Android/i,
        /webOS/i,
        /iPhone/i,
        /iPad/i,
        /iPod/i,
        /BlackBerry/i,
        /Windows Phone/i
    ];

    return toMatch.some((toMatchItem) => {
        return navigator.userAgent.match(toMatchItem);
    });
}
</script>
</html>

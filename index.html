<!DOCTYPE HTML>
<html lang="en" xmlns="">

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-CSSRCE808M"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-CSSRCE808M');
    </script>

    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ehsan Pajouheshgar</title>

    <meta name="author" content="Ehsan Pajouheshgar">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="images/favicon.png">
</head>

<body>
    <table
        style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.5%;width:63%;vertical-align:middle">
                                    <p style="text-align:center">
                                        <name>Ehsan Pajouheshgar</name>
                                    </p>
                                    <p>
                                        I am a postdoctoral researcher at EPFL Lausanne, working jointly with the
                                        <a href="https://www.epfl.ch/labs/ivrl/">Image and Visual Representation
                                            Laboratory (IVRL)</a>
                                        and the Chair of Statistical Field Theory (CSFT) with Clément Hongler.
                                        I recently completed my PhD at EPFL under the supervision of Sabine Süsstrunk.
                                        Before joining EPFL, I obtained my bachelor's degree in Computer Engineering,
                                        with a minor in Mathematics,
                                        from Sharif University of Technology in Iran.
                                    </p>

                                    <!-- <p>
                                        My research in the last years has been focused on studying Neural Cellular
                                        Automata (NCA)
                                        models. NCAs demonstrate how self-organization and complexity can emerge from
                                        simple local
                                        interactions. The advantage of NCAs over traditional Cellular Automata is that
                                        they are
                                        differentiable and can be trained with gradient-based methods.

                                        I'm interested in Computer Vision and Computer Graphics research. I like
                                        to design (bio and physics)-inspired models to tackle different problems in
                                        these fields.
                                        More recently, I am also learning and doing research on Artificial Life. I am
                                        interested in
                                        the emergence of life-like behaviors such as Solitons, Self-Organization, and
                                        Self-Replication.

                                    </p> -->
                                    <p>
                                        <b>Research interests.</b>
                                        I am broadly interested in Artificial Life and Computer Vision/Graphics, and in
                                        mixing ideas between these areas.
                                        In Artificial Life, I am interested in self-organization, self-replication, and
                                        in discovering or designing systems that exhibit unbounded, open-ended growth in
                                        complexity. In computer graphics and vision, I have worked extensively on
                                        textures and am particularly interested in the role textures play in visual
                                        perception.
                                        Much of my recent work uses Neural Cellular Automata (NCA) as a minimal,
                                        trainable model of self-organization and
                                        pattern formation.
                                    </p>
                                    <p>
                                        <b style="color:darkred">Update:</b>
                                        <b> I am looking for postdoc or research scientist positions.
                                            Feel free to reach out to discuss potential opportunities or collaborations.
                                        </b>
                                    </p>

                                    <!--                        <p>-->
                                    <!--                            During the summer of 2018, I had the opportunity to undertake an internship at <a-->
                                    <!--                                href="https://ist.ac.at/en/home/">IST Austria</a>-->
                                    <!--                            where I was mentored by Christoph Lampert. In the following year, from 2019 to 2020, I-->
                                    <!--                            worked as a Data Scientist at <a href="https://balad.ir/">Balad</a>, a dynamic company-->
                                    <!--                            dedicated to the development of advanced map and navigation software.-->
                                    <!--                        </p>-->
                                    <!--                        <p>-->
                                    <!--                            During my high school years, I developed a strong passion for Physics and dedicated-->
                                    <!--                            considerable effort to preparing for the national physics Olympiad, where I was able to-->
                                    <!--                            achieve the 7th rank among a vast pool of nearly 100 thousand participants and earn a gold-->
                                    <!--                            medal.-->
                                    <!--                            <br>-->

                                    <!--                            Throughout my bachelor's degree, I found myself deeply intrigued by the world of probability-->
                                    <!--                            and statistics. My interest led me to take part in the national statistics Olympiad, where I-->
                                    <!--                            achieved the 1st place among hundreds of participants and awarded a gold medal.-->


                                    </p>
                                    <p style="text-align:center">

                                        <a href="mailto:e.pajouheshgar@gmail.com">Email</a> &nbsp/&nbsp
                                        <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                                        <!--                            <a href="https://www.linkedin.com/in/yitao-xu-b016891b2/">Linkedin</a> &nbsp/&nbsp-->
                                        <a href="https://scholar.google.com/citations?user=bddQ6pQAAAAJ&hl=en">Google
                                            Scholar</a>
                                        &nbsp/&nbsp
                                        <a href="https://github.com/TheDevilWillBeBee">Github</a>
                                        &nbsp/&nbsp
                                        <a href="https://x.com/Esychology">Twitter</a>
                                    </p>

                                    <!-- <p style="text-align:center">
                                        <br>
                                        <b> Navigate this page </b>
                                        <br><br>
                                        <a href="#awards">Awards</a> &nbsp/&nbsp
                                        <a href="#publications">Publications</a> &nbsp/&nbsp
                                        <a href="#news">News</a>
                                    </p> -->


                                </td>
                                <td style="padding-bottom:10.5%;width:40%;max-width:40%">
                                    <video width=100% height=100% muted autoplay loop>
                                        <source src="images/growing_face_new.mp4" type="video/mp4">
                                        Your browser does not support the video tag.
                                    </video>
                                    <!--                        <a href="images/photo.jpg"><img style="width:100%;max-width:100%" alt="profile photo"-->
                                    <!--                                                        src="images/photo.jpg" class="hoverZoomLink"></a>-->
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table id="awards"
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <th style="text-align:center;" colspan="2">
                                    <heading>Awards &#127942;</heading>
                                </th>
                            </tr>
                            <tr>
                                <td><br></td>
                            </tr>
                            <tr>
                                <td>Dec. 2025</td>
                                <td><b>Distinguished PhD Thesis Award</b> From EPFL</td>
                            </tr>
                            <tr>
                                <td>Nov. 2025</td>
                                <td><b>Best Poster Award</b> From BMVC 2025 Conference</td>
                            </tr>
                            <tr>
                                <td>July. 2024</td>
                                <td><b>Best Student Paper Award</b> From ALife 2024 Conference</td>
                            </tr>
                            <tr>
                                <td>Dec. 2023</td>
                                <td><b>Teaching Assistance Excellence Award</b> From EPFL</td>
                            </tr>
                            <tr>
                                <td>Aug. 2022</td>
                                <td><b>Best Paper Award</b> From SIGGRAPH 2022 Conference</td>
                            </tr>
                            <tr>
                                <td>Oct. 2020</td>
                                <td><b>Doctoral Fellowship</b> from EDIC EPFL</td>
                            </tr>
                            <tr>
                                <td>Sept. 2019</td>
                                <td><b>Gold Medal</b> in Iranian National <b>Statistics Olympiad</b></td>
                            </tr>
                            <tr>
                                <td>Aug. 2014</td>
                                <td><b>Gold Medal</b> in Iranian National <b>Physics Olympiad</b></td>
                            </tr>

                            <tr>
                                <td><br></td>
                            </tr>
                        </tbody>
                    </table>


                    <br><br>
                    <table id="publications"
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <th colspan="2" style="text-align:center;">
                                <heading>Publication Highlights &#128220;</heading>
                            </th>

                            <tr onmouseout="meshnca_stop()" onmouseover="meshnca_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='meshnca_image'>
                                            <video width=100% height=100% muted autoplay loop>
                                                <source src="images/meshnca.mp4" type="video/mp4">
                                                Your browser does not support the video tag.
                                            </video>
                                        </div>
                                        <img src='images/meshnca.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function meshnca_start() {
                                            document.getElementById('meshnca_image').style.opacity = "1";
                                        }

                                        function meshnca_stop() {
                                            if (detectMob()) {
                                                document.getElementById('meshnca_image').style.opacity = "1";
                                            } else {
                                                document.getElementById('meshnca_image').style.opacity = "0";
                                            }
                                        }

                                        meshnca_start()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://meshnca.github.io">
                                        <papertitle>Mesh Neural Cellular Automata
                                        </papertitle>
                                    </a>
                                    <br>
                                    <strong>Ehsan Pajouheshgar*</strong>,
                                    Yitao Xu*,
                                    Alexander Mordvintsev,
                                    Eyvind Niklasson,
                                    Tong Zhang,
                                    Sabine Süsstrunk
                                    <br>
                                    <em>SIGGRAPH</em>, 2024
                                    <br>
                                    <a href="https://meshnca.github.io/">Demo</a>
                                    /
                                    <a href="https://arxiv.org/abs/2311.02820">arXiv</a>
                                    /
                                    <a href="https://github.com/IVRL/MeshNCA">code</a>
                                    <p></p>
                                    <p>
                                        MeshNCA is a type of <b>N</b>eural <b>C</b>ellular <b>A</b>utomata that can
                                        operate
                                        on cells arranged on a 3D mesh. MeshNCA can simultaneously generate multiple
                                        textures
                                        (albedo, normal, roughness, ...) for Physically-based-rendering (PBR).
                                        It also enables grafting multiple NCA models on each other to create mixture of
                                        textures.
                                        Checkout the <a href="https://meshnca.github.io/">demo</a>!
                                    </p>
                                    <p>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="noisenca_stop()" onmouseover="noisenca_start()" bgcolor="ffffd0">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='noisenca_image'>
                                            <video width=100% height=100% muted autoplay loop>
                                                <source src="images/noisenca.mp4" type="video/mp4">
                                                Your browser does not support the video tag.
                                            </video>
                                        </div>
                                        <img src='images/noisenca.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function noisenca_start() {
                                            document.getElementById('noisenca_image').style.opacity = "1";
                                        }

                                        function noisenca_stop() {
                                            if (detectMob()) {
                                                document.getElementById('noisenca_image').style.opacity = "1";
                                            } else {
                                                document.getElementById('noisenca_image').style.opacity = "0";
                                            }
                                        }

                                        noisenca_start()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://noisenca.github.io">
                                        <papertitle>NoiseNCA: Noisy Seed Improves Spatio-Temporal Continuity of Neural
                                            Cellular
                                            Automata
                                        </papertitle>
                                    </a>
                                    <br>
                                    <strong>Ehsan Pajouheshgar</strong>,
                                    Yitao Xu,
                                    Sabine Süsstrunk
                                    <br>
                                    <em>Artificial Life (ALife)</em>, 2024
                                    <font color="red"> <strong> (Best Student Paper Award) </strong> </font>
                                    <br>
                                    <a href="https://noisenca.github.io/">Demo</a>
                                    /
                                    <a href="https://arxiv.org/abs/2404.06279">arXiv</a>
                                    /
                                    <a href="https://github.com/IVRL/NoiseNCA">code</a>
                                    <p></p>
                                    <p>
                                        We propose a small change to Neural Cellular Automata (NCA) and show that the
                                        update rule
                                        learned by NoiseNCA
                                        actually correspond to a continuous space-time Partial Differential Equation
                                        (PDE).
                                        Utilizing this emergent space-time continuity, NoiseNCA allows changing the
                                        speed of the
                                        pattern formation
                                        and the scale of the patterns at inference time.
                                        Checkout the <a href="https://noisenca.github.io/">demo</a>!
                                    </p>
                                    <p>
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="dynca_stop()" onmouseover="dynca_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='dynca_image'>
                                            <video width=100% height=100% muted autoplay loop>
                                                <source src="images/dynca.mp4" type="video/mp4">
                                                Your browser does not support the video tag.
                                            </video>
                                        </div>
                                        <img src='images/dynca.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function dynca_start() {
                                            document.getElementById('dynca_image').style.opacity = "1";
                                        }

                                        function dynca_stop() {
                                            if (detectMob()) {
                                                document.getElementById('dynca_image').style.opacity = "1";
                                            } else {
                                                document.getElementById('dynca_image').style.opacity = "0";
                                            }
                                        }

                                        dynca_start()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://dynca.github.io">
                                        <papertitle>DyNCA: Real-time Dynamic Texture Synthesis Using Neural Cellular
                                            Automata
                                        </papertitle>
                                    </a>
                                    <br>
                                    <strong>Ehsan Pajouheshgar*</strong>,
                                    Yitao Xu*,
                                    Tong Zhang,
                                    Sabine Süsstrunk
                                    <br>
                                    <em>CVPR</em>, 2023
                                    <br>
                                    <a href="https://dynca.github.io/">Demo</a>
                                    /
                                    <a href="https://arxiv.org/abs/2211.11417">arXiv</a>
                                    /
                                    <a href="https://github.com/IVRL/DyNCA">code</a>
                                    <p></p>
                                    <p>
                                        Dynamic Neural Cellular Automata (DyNCA), is a method that enables real-time and
                                        controllable dynamic texture synthesis. Checkout the <a
                                            href="https://dynca.github.io/">demo</a>!
                                    </p>
                                    <p>
                                    </p>
                                </td>
                            </tr>


                            <tr bgcolor="ffffd0">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <img src='images/clipasso.png' width="160">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://clipasso.github.io/clipasso/">
                                        <papertitle>CLIPasso: Semantically-Aware Object Sketching
                                        </papertitle>
                                    </a>
                                    <br>
                                    Yael Vinker, <strong>Ehsan Pajouheshgar</strong>, Jessica Y. Bo, Roman Bachmann,
                                    <br>
                                    Amit Haim Bermano, Daniel Cohen-Or, Amir Zamir, Ariel Shamir
                                    <br>
                                    <em>SIGGRAPH</em>, 2022
                                    <font color="red"> <strong> (Best Paper Award) </strong> </font>
                                    <br>
                                    <a href="https://clipasso.github.io/clipasso/">Project Page</a> /
                                    <a href="https://replicate.com/yael-vinker/clipasso">Demo</a> /
                                    <a href="https://arxiv.org/abs/2202.05822">arXiv</a> /
                                    <a href="https://github.com/yael-vinker/CLIPasso">code</a>
                                    <p></p>
                                    <p>
                                        Our work converts an image of an object to a sketch, allowing for varying levels
                                        of
                                        abstraction, while preserving its key visual features.
                                    </p>
                                    <p>
                                    </p>
                                </td>

                            </tr>


                        </tbody>


                    </table>

                    <br><br>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <th colspan="2" style="text-align:center;">
                                <heading>Publications &#128220;</heading>
                            </th>

                            <tr onmouseout="vnca_stop()" onmouseover="vnca_start()" bgcolor="ffffd0">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id="vnca_image" style="opacity: 0;"><video width="100%"
                                                height="100%" muted="" autoplay="" loop="">
                                                <source src="images/vnca_video.mp4" type="video/mp4">
                                                Your browser does not support the video tag.
                                            </video></div>
                                        <img src="images/vnca_img.png" width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function vnca_start() {
                                            document.getElementById('vnca_image').style.opacity = "1";
                                        }

                                        function vnca_stop() {
                                            document.getElementById('vnca_image').style.opacity = "0";
                                        }
                                        vnca_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://pajouheshgar.github.io/">
                                        <papertitle>Volumetric Temporal Texture Synthesis for Smoke Stylization using
                                            Neural Cellular Automata</papertitle>
                                    </a>
                                    <br>
                                    Dongqing Wang,
                                    <strong>Ehsan Pajouheshgar</strong>,
                                    Yitao Xu,
                                    Tong Zhang,
                                    Sabine Süsstrunk
                                    <br>
                                    <em>BMVC</em> 2025 <font color="red"> <strong> (Best Poster Award) </strong> </font>
                                    <br>
                                    <a href="https://arxiv.org/abs/2502.09631">arXiv</a>
                                    <p></p>
                                    <p>VNCA is a novel model for efficient volumetric style transfer that synthesizes
                                        multi-view consistent stylizing features on the target smoke in real-time, while
                                        exhibiting temporally coherent transitions between stylized frame.</p>

                                </td>
                            </tr>

                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <img src='images/clipasso.png' width="160">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://clipasso.github.io/clipasso/">
                                        <papertitle>The Mokume Dataset and Inverse Modeling of Solid Wood Textures
                                        </papertitle>
                                    </a>
                                    <br>
                                    Maria Larsson, Hodaka Yamaguchi, <strong>Ehsan Pajouheshgar</strong>, I-Chao Shen,
                                    Kenji Tojo,
                                    Chia-Ming Chang, Lars Hansson, Olof Broman, Takashi Ijiri, Ariel Shamir, Wenzel
                                    Jakob, and Takeo Igarashi
                                    <br>
                                    <em>SIGGRAPH</em>, 2025
                                    <br>
                                    <a href="https://mokumeproject.github.io/">Project Page</a> /
                                    <a href="https://dl.acm.org/doi/10.1145/3730874">Proceedings</a> /
                                    <a href="https://github.com/marialarsson/mokumeproject">Code</a>
                                    <a href="https://zenodo.org/records/15588748">Dataset</a>
                                    <p></p>
                                    <p>
                                        We introduce Mokume, a dataset of 190 solid wood samples with high-resolution
                                        photos, ring annotations, and volumetric CT scans for realistic wood texturing.
                                        Using this data, we reconstruct a 3D growth field and synthesize volumetric
                                        color textures from a few exterior photos, combining procedural modeling with
                                        Neural Cellular Automata (NCA) to closely match real wood.
                                    </p>
                                    <p>
                                    </p>
                                </td>

                            </tr>


                            <tr onmouseout="emdnca_stop()" onmouseover="emdnca_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='emd_nca_image'>
                                            <video width=100% height=100% muted autoplay loop>
                                                <source src="images/emergent_dynamics_nca.mp4" type="video/mp4">
                                                Your browser does not support the video tag.
                                            </video>
                                        </div>
                                        <img src='images/emergent_dynamics_nca.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function emdnca_start() {
                                            document.getElementById('emd_nca_image').style.opacity = "1";
                                        }

                                        function emdnca_stop() {
                                            if (detectMob()) {
                                                document.getElementById('emd_nca_image').style.opacity = "1";
                                            } else {
                                                document.getElementById('emd_nca_image').style.opacity = "0";
                                            }
                                        }

                                        emdnca_start()
                                    </script>
                                </td>

                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2404.06406">
                                        <papertitle>Emergent Dynamics in Neural Cellular Automata
                                        </papertitle>
                                    </a>
                                    <br>
                                    Yitao Xu, <strong>Ehsan Pajouheshgar</strong>, Sabine Süsstrunk
                                    <br>
                                    <em>Artificial Life (ALife)</em>, 2024
                                    <br>
                                    <a href="https://arxiv.org/abs/2404.06406">arXiv</a> /
                                    <a href="">Coming Soon</a>
                                    <p></p>
                                    <p>
                                        Trained Neural Cellular Automata (NCA) models exhibit many emergent behaviors,
                                        such as
                                        self-organization, and spontaneous motion. In this paper we investigate the
                                        spontaneous
                                        motion property
                                        of NCAs. We find that the ratio between the number of channels in the cell state
                                        and the number of hidden neurons in the update rule is a key factor that
                                        controls the
                                        NCA stability and emergent motion in the NCA generated patterns.

                                    </p>
                                    <p>
                                    </p>
                                </td>

                            </tr>

                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <img src='images/lelsd.png' width="160">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2111.12583">
                                        <papertitle>Optimizing Latent Space Directions For GAN-based Local Image Editing
                                        </papertitle>
                                    </a>
                                    <br>
                                    <strong>Ehsan Pajouheshgar</strong>, Tong Zhang, Sabine Süsstrunk
                                    <br>
                                    <em>ICASSP</em>, 2022
                                    <br>
                                    <a href="https://arxiv.org/abs/2111.12583">arXiv</a> /
                                    <a href="https://github.com/IVRL/LELSD">code</a>
                                    <p></p>
                                    <p>
                                        We introduce the Locally Effective Latent Space Direction (LELSD) framework, a
                                        novel
                                        approach to localized image editing in Generative Adversarial Networks (GANs),
                                        which
                                        utilizes a new objective function incorporating supervision from a pre-trained
                                        segmentation
                                        network.
                                    </p>
                                    <p>
                                    </p>
                                </td>

                            </tr>

                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <img src='images/ptf.png' width="160">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/pdf/1812.02984.pdf">
                                        <papertitle>Back to square one: probabilistic trajectory forecasting without
                                            bells and
                                            whistles
                                        </papertitle>
                                    </a>
                                    <br>
                                    <strong>Ehsan Pajouheshgar</strong>, Christoph H. Lampert
                                    <br>
                                    <em>NeurIPS 2018</em>,
                                    <small> (Workshop on Modeling and Decision-Making in the Spatiotemporal
                                        Domain)</small>
                                    <br>
                                    <a href="https://arxiv.org/abs/2111.12583">arXiv</a>
                                    <p></p>
                                    <p>
                                        We present an uncomplicated non-parametric baseline that attains the lowest
                                        error based on a
                                        widely adopted metric within the field. This serves to demonstrate the
                                        misleading nature of
                                        this particular metric.
                                    </p>
                                    <p>
                                    </p>
                                </td>
                            </tr>


                        </tbody>


                    </table>


                    <table id="news"
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <th style="text-align:center;" colspan="2">
                                    <heading>News &#128240;</heading>
                                </th>
                            </tr>
                            <tr>
                                <td><br></td>
                            </tr>
                            <tr>
                                <td>Dec. 2025</td>
                                <td>I have received the <b>Distinguished PhD Thesis Award</b> from EPFL.</td>
                            </tr>
                            <tr>
                                <td>Nov. 2025</td>
                                <td>VNCA won the <b>Best Poster Award</b> at BMVC 2025.</td>
                            </tr>
                            <tr>
                                <td>Aug. 2025</td>
                                <td>I have started a joint postdoc between IVRL and CSFT at EPFL</td>
                            </tr>
                            <tr>
                                <td>July. 2024</td>
                                <td>NoiseNCA won the <b>Best Student Paper Award</b> at ALife 2024.</td>
                            </tr>

                            <tr>
                                <td>July. 2024</td>
                                <td>I will attend <b>Siggraph 2024</b> Conference. Visa problems...</td>
                            </tr>
                            <tr>
                                <td>July. 2024</td>
                                <td>I will attend <b>Artificial Life (ALife 2024)</b> Conference. Let's meet there!</td>
                            </tr>
                            <tr>
                                <td>May. 2023</td>
                                <td>Two papers accepted to ALife 2024.</td>
                            </tr>
                            <tr>
                                <td>Mar. 2023</td>
                                <td>MeshNCA was accepted as a journal paper to SIGGRAPH 2024.</td>
                            </tr>


                            <tr>
                                <td><br></td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <br>
                                    <p style="text-align:right;font-size:small;">
                                        <a href="https://jonbarron.info/">Webpage Template</a>
                                        <br>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </td>
            </tr>
    </table>
</body>
<script>
    function detectMob() {
        return false;
        const toMatch = [
            /Android/i,
            /webOS/i,
            /iPhone/i,
            /iPad/i,
            /iPod/i,
            /BlackBerry/i,
            /Windows Phone/i
        ];

        return toMatch.some((toMatchItem) => {
            return navigator.userAgent.match(toMatchItem);
        });
    }
</script>

</html>